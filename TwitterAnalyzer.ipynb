{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manasi200/Twitter-Sentiment-Analyzer/blob/main/TwitterAnalyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgocAqaB2fXV"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "import socket\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E3zXyPI5WLi"
      },
      "outputs": [],
      "source": [
        "consumer_key='___________________'\n",
        "consumer_secret='__________________'\n",
        "access_token ='______________________________'\n",
        "access_secret='__________________________'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu4Jr6TN6EeL"
      },
      "outputs": [],
      "source": [
        "class TweetsListener(StreamListener):\n",
        "  # tweet object listens for the tweets\n",
        "  def __init__(self, csocket):\n",
        "    self.client_socket = csocket\n",
        "  def on_data(self, data):\n",
        "    try:  \n",
        "      msg = json.loads( data )\n",
        "      print(\"new message\")\n",
        "      # if tweet is longer than 140 characters\n",
        "      if \"extended_tweet\" in msg:\n",
        "        # add at the end of each tweet \"t_end\" \n",
        "        self.client_socket\\\n",
        "            .send(str(msg['extended_tweet']['full_text']+\"t_end\")\\\n",
        "            .encode('utf-8'))         \n",
        "        print(msg['extended_tweet']['full_text'])\n",
        "      else:\n",
        "        # add at the end of each tweet \"t_end\" \n",
        "        self.client_socket\\\n",
        "            .send(str(msg['text']+\"t_end\")\\\n",
        "            .encode('utf-8'))\n",
        "        print(msg['text'])\n",
        "      return True\n",
        "    except BaseException as e:\n",
        "        print(\"Error on_data: %s\" % str(e))\n",
        "    return True\n",
        "  def on_error(self, status):\n",
        "    print(status)\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bcY2Kz66GR0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sendData(c_socket, keyword):\n",
        "  print('start sending data from Twitter to socket')\n",
        "  # authentication based on the credentials\n",
        "  auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "  auth.set_access_token(access_token, access_secret)\n",
        "  # start sending data from the Streaming API \n",
        "  twitter_stream = Stream(auth, TweetsListener(c_socket))\n",
        "  twitter_stream.filter(track = keyword, languages=[\"en\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-dClx3_6NWX",
        "outputId": "31022d79-c1c9-4b57-9931-e665a4d8e0ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "socket is ready\n",
            "socket is listening\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # server (local machine) creates listening socket\n",
        "    s = socket.socket()\n",
        "    host = \"0.0.0.0\"    \n",
        "    port = 5555\n",
        "    s.bind((host, port))\n",
        "    print('socket is ready')\n",
        "    # server (local machine) listens for connections\n",
        "    s.listen(4)\n",
        "    print('socket is listening')\n",
        "    # return the socket and the address on the other side of the connection (client side)\n",
        "    c_socket, addr = s.accept()\n",
        "    print(\"Received request from: \" + str(addr))\n",
        "    # select here the keyword for the tweet data\n",
        "    sendData(c_socket, keyword = ['piano'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHoQyxwY6vNt"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c_gbv166zBN"
      },
      "outputs": [],
      "source": [
        "def preprocessing(lines):\n",
        "    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"word\"))\n",
        "    words = words.na.replace('', None)\n",
        "    words = words.na.drop()\n",
        "    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0HhyuYY63b8"
      },
      "outputs": [],
      "source": [
        "# text classification\n",
        "def polarity_detection(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "def subjectivity_detection(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "def text_classification(words):\n",
        "    # polarity detection\n",
        "    polarity_detection_udf = udf(polarity_detection, StringType())\n",
        "    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n",
        "    # subjectivity detection\n",
        "    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n",
        "    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcqBUuoa66yP"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # create Spark session\n",
        "    spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
        "    # read the tweet data from socket\n",
        "    lines = spark.readStream.format(\"socket\").option(\"host\", \"0.0.0.0\").option(\"port\", 5555).load()\n",
        "    # Preprocess the data\n",
        "    words = preprocessing(lines)\n",
        "    # text classification to define polarity and subjectivity\n",
        "    words = text_classification(words)\n",
        "    words = words.repartition(1)\n",
        "    query = words.writeStream.queryName(\"all_tweets\")\\\n",
        "        .outputMode(\"append\").format(\"parquet\")\\\n",
        "        .option(\"path\", \"./parc\")\\\n",
        "        .option(\"checkpointLocation\", \"./check\")\\\n",
        "        .trigger(processingTime='60 seconds').start()\n",
        "    query.awaitTermination()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWxuk7XV0xaGyiRDHWcND7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}